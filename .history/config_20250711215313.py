import os
from typing import Optional
try:
    from pydantic_settings import BaseSettings
except ImportError:
    from pydantic import BaseSettings

class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    
    # ðŸ” OpenAI ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ ê°€ì ¸ì˜¤ê¸°)
    openai_api_key: Optional[str] = None
    
    # ðŸ“Š ë²¡í„° DB ì„¤ì • (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ)
    chroma_db_path: str = "/data"
    
    # ðŸŒ ì„œë²„ ì„¤ì •
    host: str = "0.0.0.0"
    port: int = 8000  # FastMCP ì„œë²„ í¬íŠ¸
    
    # ðŸ“ ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_dir: str = "/app/logs"  # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ë¡œê·¸ ê²½ë¡œ
    
    # ðŸš€ MCP ì„¤ì •
    mcp_server_name: str = "FastMCP Prompt Enhancement Server"
    mcp_version: str = "2.0.0"
    
    # ðŸ” ChromaDB ì„¤ì •
    chroma_host: str = "chromadb"  # Docker Compose ì„œë¹„ìŠ¤ëª…
    chroma_port: int = 8000       # ChromaDB í¬íŠ¸
    chroma_collection_name: str = "prompts"
    
    # ðŸ§  AI ì„¤ì •
    max_context_length: int = 5
    similarity_threshold: float = 0.7
    
    # ðŸ“ˆ ë¶„ì„ ì„¤ì •
    enable_advanced_analytics: bool = True
    clustering_algorithm: str = "kmeans"
    max_clusters: int = 10
    
    # âš¡ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    # ìºì‹± ì„¤ì •
    enable_search_cache: bool = True
    cache_ttl_seconds: int = 300  # 5ë¶„
    max_cache_size: int = 1000    # ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
    
    # ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì •
    max_concurrent_requests: int = 10
    request_timeout_seconds: int = 30
    
    # ìž„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
    embedding_batch_size: int = 50
    embedding_parallel_workers: int = 4
    
    # íŒŒì¼ ì¸ë±ì‹± ìµœì í™”
    max_file_size_mb: int = 10
    parallel_file_processing: bool = True
    chunk_processing_batch_size: int = 100
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§
    db_connection_pool_size: int = 10
    db_connection_timeout: int = 5
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    enable_memory_optimization: bool = True
    garbage_collection_threshold: int = 1000  # ì²˜ë¦¬ëœ ìš”ì²­ ìˆ˜
    
    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    enable_performance_monitoring: bool = True
    slow_query_threshold_seconds: float = 1.0
    
    # API ì†ë„ ì œí•œ
    rate_limit_per_minute: int = 100
    rate_limit_burst_size: int = 10
    
    # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ìµœì í™”
    text_chunk_size: int = 1000
    text_chunk_overlap: int = 200
    max_text_length: int = 50000
    
    # ê²€ìƒ‰ ìµœì í™”
    semantic_search_weight: float = 0.7
    keyword_search_weight: float = 0.3
    time_decay_factor: float = 0.1
    complexity_weight: float = 0.1
    
    # ë¦¬ì†ŒìŠ¤ ì œí•œ
    max_memory_usage_mb: int = 2048
    max_cpu_usage_percent: int = 80
    
    # ðŸ”„ í”¼ë“œë°± ì‹œìŠ¤í…œ ì„¤ì •
    feedback_learning_rate: float = 0.1  # í•™ìŠµë¥  (0.0 ~ 1.0)
    feedback_decay_rate: float = 0.95  # ì‹œê°„ì— ë”°ë¥¸ í”¼ë“œë°± ê°€ì¤‘ì¹˜ ê°ì†Œ
    min_feedback_count: int = 3  # ìµœì†Œ í”¼ë“œë°± ìˆ˜
    feedback_confidence_threshold: float = 0.7  # í”¼ë“œë°± ì‹ ë¢°ë„ ìž„ê³„ê°’
    enable_feedback_learning: bool = True  # í”¼ë“œë°± í•™ìŠµ í™œì„±í™”
    feedback_retention_days: int = 90  # í”¼ë“œë°± ë³´ì¡´ ê¸°ê°„
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = Settings()

# í˜¸í™˜ì„±ì„ ìœ„í•œ Config í´ëž˜ìŠ¤ ìƒì„±
class Config:
    """ì •ì  ì„¤ì • í´ëž˜ìŠ¤ (í˜¸í™˜ì„± ìœ ì§€)"""
    
    @property
    def FEEDBACK_LEARNING_RATE(self) -> float:
        return settings.feedback_learning_rate
        
    @property
    def FEEDBACK_DECAY_RATE(self) -> float:
        return settings.feedback_decay_rate
        
    @property
    def MIN_FEEDBACK_COUNT(self) -> int:
        return settings.min_feedback_count
        
    @property
    def FEEDBACK_CONFIDENCE_THRESHOLD(self) -> float:
        return settings.feedback_confidence_threshold 