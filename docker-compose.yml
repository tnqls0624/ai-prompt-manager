version: "3.8"

services:
  # DeepSeek R1 ë¡œì»¬ LLM ì„œë¹„ìŠ¤
  deepseek-r1:
    image: ollama/ollama:latest
    container_name: deepseek-r1-server
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_PORT=11434
      - OLLAMA_MAX_LOADED_MODELS=2 # ë™ì‹œ ë¡œë“œ ëª¨ë¸ ìˆ˜ ì¦ê°€
      - OLLAMA_NUM_PARALLEL=4 # ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€
    volumes:
      - ./data/ollama:/root/.ollama
    restart: unless-stopped
    networks:
      - mcp-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    # ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
    deploy:
      resources:
        limits:
          memory: 8G # ë©”ëª¨ë¦¬ ì œí•œ
        reservations:
          memory: 4G # ìµœì†Œ ë©”ëª¨ë¦¬ ë³´ì¥
    # GPU ì§€ì› (ì„ íƒì‚¬í•­)
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  # ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤ (ìš°ì„  ì‹œì‘)
  chromadb:
    image: chromadb/chroma:latest
    container_name: chromadb-server
    ports:
      - "8001:8000"
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
      - CHROMA_SERVER_CORS_ALLOW_ORIGINS=["*"]
      # ì„±ëŠ¥ ìµœì í™” ì„¤ì •
      - CHROMA_SERVER_MAX_BATCH_SIZE=1000 # ë°°ì¹˜ í¬ê¸° ì¦ê°€
      - CHROMA_SERVER_THREAD_POOL_SIZE=10 # ìŠ¤ë ˆë“œ í’€ í¬ê¸° ì¦ê°€
    volumes:
      # ğŸ”’ í˜¸ìŠ¤íŠ¸ ê²½ë¡œì— ì§ì ‘ ë°”ì¸ë”© (ë°ì´í„° ì•ˆì „ì„±)
      - ./data/chroma:/data
      # ê°œë°œ í™˜ê²½ìš© ë°±ì—… ë””ë ‰í† ë¦¬
      - ./backups/chroma:/backups
    restart: unless-stopped
    networks:
      - mcp-network
    # ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: "2"
        reservations:
          memory: 2G
          cpus: "1"

  # FastMCP ì„œë²„ (ChromaDB ì¤€ë¹„ í›„ ì‹œì‘)
  fastmcp-server:
    build: .
    container_name: fastmcp-prompt-enhancement
    ports:
      - "8000:8000" # SSE ëª¨ë“œë¥¼ ìœ„í•œ í¬íŠ¸ ë…¸ì¶œ
    environment:
      # ğŸ” OpenAI API ì„¤ì • (ì„ íƒì‚¬í•­)
      - OPENAI_API_KEY=${OPENAI_API_KEY}

      # ğŸ¤– ì„ë² ë”© ëª¨ë¸ ì„¤ì •
      - EMBEDDING_MODEL_TYPE=${EMBEDDING_MODEL_TYPE:-deepseek}
      - DEEPSEEK_API_BASE=http://deepseek-r1:11434
      - DEEPSEEK_EMBEDDING_MODEL=${DEEPSEEK_EMBEDDING_MODEL:-nomic-embed-text}
      - DEEPSEEK_LLM_MODEL=${DEEPSEEK_LLM_MODEL:-r1-1776:latest}

      # ğŸ“Š ChromaDB ì—°ê²° ì„¤ì •
      - CHROMA_HOST=chromadb
      - CHROMA_PORT=8000
      - CHROMA_DB_PATH=/data

      # ğŸ“ ë¡œê¹… ì„¤ì •
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - LOG_DIR=/data/logs

      # ğŸš€ MCP ì„¤ì •
      - MCP_SERVER_NAME=FastMCP Prompt Enhancement Server
      - MCP_VERSION=2.0.0

      # ğŸ§  AI ì„¤ì •
      - MAX_CONTEXT_LENGTH=${MAX_CONTEXT_LENGTH:-5}
      - SIMILARITY_THRESHOLD=${SIMILARITY_THRESHOLD:-0.7}

      # ğŸ“ˆ ë¶„ì„ ì„¤ì •
      - ENABLE_ADVANCED_ANALYTICS=${ENABLE_ADVANCED_ANALYTICS:-true}
      - CLUSTERING_ALGORITHM=${CLUSTERING_ALGORITHM:-kmeans}
      - MAX_CLUSTERS=${MAX_CLUSTERS:-10}

      # âš¡ ì„±ëŠ¥ ìµœì í™” í™˜ê²½ë³€ìˆ˜ ì¶”ê°€
      - MAX_CONCURRENT_REQUESTS=100
      - MAX_CONCURRENT_FILES=200
      - EMBEDDING_BATCH_SIZE=100
      - CHROMA_BATCH_SIZE=500
      - ENABLE_PARALLEL_INDEXING=true
    volumes:
      # ğŸ—‚ï¸ ë¡œê·¸ ë° ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ë³¼ë¥¨ ë§ˆìš´íŠ¸
      - ./data:/data

      # ğŸ¯ ì„ íƒì  í”„ë¡œì íŠ¸ ë§ˆìš´íŠ¸ (ì›í•˜ëŠ” í”„ë¡œì íŠ¸ë§Œ ì¶”ê°€)
      # ì „ì²´ í”„ë¡œì íŠ¸ í´ë” ë§ˆìš´íŠ¸ (ëª¨ë“  í”„ë¡œì íŠ¸ ì¸ë±ì‹±)
      # - /Users/soobeen/Desktop/Project:/host_projects:ro

      # ğŸ‘‡ íŠ¹ì • í”„ë¡œì íŠ¸ë§Œ ì„ íƒì ìœ¼ë¡œ ë§ˆìš´íŠ¸í•˜ë ¤ë©´ ì•„ë˜ ì˜ˆì‹œì²˜ëŸ¼ ì‚¬ìš©í•˜ì„¸ìš”
      # ì›í•˜ëŠ” í”„ë¡œì íŠ¸ í´ë”ë§Œ ê°œë³„ì ìœ¼ë¡œ ë§ˆìš´íŠ¸:
      - /Users/soobeen/Desktop/Project/lovechedule-app:/host_projects/lovechedule-app:ro
      - /Users/soobeen/Desktop/Project/lovechedule:/host_projects/lovechedule:ro
      # - /Users/soobeen/Desktop/Project/web-frontend:/host_projects/web-frontend:ro
      # - /Users/soobeen/Desktop/Project/api-backend:/host_projects/api-backend:ro

      # ğŸ“ ì‚¬ìš© ë°©ë²•:
      # 1. ìœ„ ì£¼ì„ì„ í•´ì œí•˜ê³  ì‹¤ì œ í”„ë¡œì íŠ¸ ê²½ë¡œë¡œ ìˆ˜ì •
      # 2. ì›í•˜ëŠ” í”„ë¡œì íŠ¸ ë¼ì¸ë§Œ í™œì„±í™”
      # 3. docker-compose up -d ë¡œ ì¬ì‹œì‘

      # ğŸ” ì˜ˆì‹œ: mcp-server í”„ë¡œì íŠ¸ë§Œ ì¸ë±ì‹±í•˜ê³  ì‹¶ë‹¤ë©´
      # - /Users/soobeen/Desktop/Project/mcp-server:/host_projects/mcp-server:ro
    restart: unless-stopped
    depends_on:
      - chromadb
      - deepseek-r1
    networks:
      - mcp-network
    # ë¦¬ì†ŒìŠ¤ ì œí•œ ì„¤ì •
    deploy:
      resources:
        limits:
          memory: 6G
          cpus: "4"
        reservations:
          memory: 3G
          cpus: "2"

  # Prometheus (metrics) - optional
  prometheus:
    image: prom/prometheus:latest
    container_name: mcp-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    restart: unless-stopped
    depends_on:
      - fastmcp-server
    networks:
      - mcp-network

  # Grafana (dashboard) - optional
  grafana:
    image: grafana/grafana:latest
    container_name: mcp-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
    volumes:
      - ./monitoring/grafana:/var/lib/grafana
      - ./monitoring/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/provisioning/dashboards:/etc/grafana/dashboards:ro
      - ./monitoring/provisioning/dashboards:/var/lib/grafana/dashboards:ro
    restart: unless-stopped
    depends_on:
      - prometheus
    networks:
      - mcp-network

networks:
  mcp-network:
    driver: bridge
# í˜¸ìŠ¤íŠ¸ ë°”ì¸ë”© ì‚¬ìš©ìœ¼ë¡œ volumes ì„¹ì…˜ ì œê±°
