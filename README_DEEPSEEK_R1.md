# ðŸš€ DeepSeek R1 ë¡œì»¬ ìž„ë² ë”© ì„¤ì •

OpenAI API ë¹„ìš© ì—†ì´ ë¡œì»¬ì—ì„œ DeepSeek R1 ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìž„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.

## ðŸ“‹ ì„¤ì • ë°©ë²•

### 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •

`.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•˜ì„¸ìš”:

```bash
# .env íŒŒì¼ ìƒì„±
cat > .env << 'EOF'
# ðŸ¤– ìž„ë² ë”© ëª¨ë¸ ì„¤ì •
EMBEDDING_MODEL_TYPE=deepseek

# ðŸš€ DeepSeek R1 ëª¨ë¸ ì„¤ì •
DEEPSEEK_MODEL_NAME=r1-1776:latest

# ðŸ“ ë¡œê¹… ì„¤ì •
LOG_LEVEL=INFO

# ðŸ“Š ë¶„ì„ ì„¤ì •
ENABLE_ADVANCED_ANALYTICS=true
CLUSTERING_ALGORITHM=kmeans
MAX_CLUSTERS=10

# ðŸ§  AI ì„¤ì •
MAX_CONTEXT_LENGTH=5
SIMILARITY_THRESHOLD=0.7
EOF
```

### 2. Docker ì„œë¹„ìŠ¤ ì‹œìž‘

```bash
# Docker ì„œë¹„ìŠ¤ ì‹œìž‘
docker-compose up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker ps | grep "deepseek\|fastmcp\|chromadb"
```

### 3. DeepSeek R1 ëª¨ë¸ ì„¤ì¹˜

```bash
# DeepSeek R1 ëª¨ë¸ ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x scripts/setup_deepseek_r1.sh
./scripts/setup_deepseek_r1.sh
```

### 4. ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘

```bash
# FastMCP ì„œë²„ ìž¬ì‹œìž‘í•˜ì—¬ ìƒˆ ì„¤ì • ì ìš©
docker-compose restart fastmcp-server
```

## ðŸ”§ ëª¨ë¸ ì„¤ì •

### ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤

1. **r1-1776:latest** - ì‹¤ì œ DeepSeek R1 ëª¨ë¸ (ì¶”ì²œ, 42GB)
2. **deepseek-coder:7b** - ì½”ë”© íŠ¹í™” ëª¨ë¸ (7B íŒŒë¼ë¯¸í„°)
3. **deepseek-coder:33b** - ë” í° ëª¨ë¸ (GPU í•„ìš”, 33B íŒŒë¼ë¯¸í„°)

### ëª¨ë¸ ë³€ê²½ ë°©ë²•

```bash
# ë‹¤ë¥¸ ëª¨ë¸ ì„¤ì¹˜
docker exec deepseek-r1-server ollama pull deepseek-coder:33b

# .env íŒŒì¼ì—ì„œ ëª¨ë¸ëª… ë³€ê²½
DEEPSEEK_MODEL_NAME=deepseek-coder:33b

# ì„œë¹„ìŠ¤ ìž¬ì‹œìž‘
docker-compose restart fastmcp-server
```

## ðŸ–¥ï¸ GPU ì§€ì› (ì„ íƒì‚¬í•­)

GPUê°€ ìžˆë‹¤ë©´ `docker-compose.yml`ì—ì„œ GPU ì§€ì›ì„ í™œì„±í™”í•˜ì„¸ìš”:

```yaml
# docker-compose.ymlì—ì„œ ì£¼ì„ í•´ì œ
deepseek-r1:
  # ... ê¸°íƒ€ ì„¤ì • ...
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

## ðŸ“Š ì„±ëŠ¥ ë¹„êµ

| ëª¨ë¸        | ë¹„ìš©    | ì†ë„    | í’ˆì§ˆ    | í”„ë¼ì´ë²„ì‹œ |
| ----------- | ------- | ------- | ------- | ---------- |
| OpenAI API  | ðŸ’° ìœ ë£Œ | âš¡ ë¹ ë¦„ | ðŸŒŸ ë†’ìŒ | âš ï¸ ì™¸ë¶€    |
| DeepSeek R1 | ðŸ†“ ë¬´ë£Œ | ðŸ¢ ëŠë¦¼ | â­ ì¤‘ê°„ | ðŸ”’ ë¡œì»¬    |

## ðŸ” ë¬¸ì œ í•´ê²°

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

```bash
# ì»¨í…Œì´ë„ˆ ë¡œê·¸ í™•ì¸
docker logs deepseek-r1-server -f

# ìˆ˜ë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec -it deepseek-r1-server ollama pull deepseek-coder:7b
```

### ìž„ë² ë”© ìƒì„± ì‹¤íŒ¨

```bash
# API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
curl http://localhost:11434/api/tags

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker exec deepseek-r1-server ollama list
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ë” ìž‘ì€ ëª¨ë¸ ì‚¬ìš©
DEEPSEEK_MODEL_NAME=llama2:7b

# ë˜ëŠ” Docker ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
# docker-compose.ymlì—ì„œ ë©”ëª¨ë¦¬ ì œí•œ ì¶”ê°€
```

## ðŸ’¡ íŒ

1. **ì²« ì‹¤í–‰ ì‹œ**: ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ ì¸í•´ ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤
2. **GPU ê¶Œìž¥**: ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•´ GPU ì‚¬ìš©ì„ ê¶Œìž¥í•©ë‹ˆë‹¤
3. **ëª¨ë¸ í¬ê¸°**: ë©”ëª¨ë¦¬ì— ë§žëŠ” ëª¨ë¸ í¬ê¸°ë¥¼ ì„ íƒí•˜ì„¸ìš”
4. **ë¡œì»¬ ìš°ì„ **: ê°œì¸ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ ë¡œì»¬ ëª¨ë¸ì„ ìš°ì„  ì‚¬ìš©í•˜ì„¸ìš”

## ðŸš€ í™•ì¸ ë°©ë²•

```bash
# ìž„ë² ë”© ì„œë¹„ìŠ¤ í…ŒìŠ¤íŠ¸
docker exec fastmcp-prompt-enhancement python -c "
import asyncio
from services.vector_service import VectorService

async def test_embedding():
    vs = VectorService()
    if vs.embeddings:
        print('âœ… ìž„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ')
        print(f'ðŸ“Š ëª¨ë¸ íƒ€ìž…: {vs.embedding_model_type}')
    else:
        print('âŒ ìž„ë² ë”© ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨')

asyncio.run(test_embedding())
"
```

ì´ì œ OpenAI API ì—†ì´ë„ ë¡œì»¬ì—ì„œ ìž„ë² ë”©ì„ ìƒì„±í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤! ðŸŽ‰
