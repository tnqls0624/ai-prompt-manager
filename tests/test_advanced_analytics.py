#!/usr/bin/env python3
"""
ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

scikit-learnì„ í™œìš©í•œ ìƒˆë¡œìš´ ë¶„ì„ ê¸°ëŠ¥ë“¤ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
- í”„ë¡¬í”„íŠ¸ í´ëŸ¬ìŠ¤í„°ë§
- TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ  
- íŠ¸ë Œë“œ ë¶„ì„
- ê³ ê¸‰ ìœ ì‚¬ë„ ê³„ì‚°
"""

import asyncio
import os
import sys
import logging
from datetime import datetime, timedelta

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.vector_service import VectorService
from services.advanced_analytics import AdvancedAnalyticsService
from services.prompt_enhancement_service import PromptEnhancementService
from models.prompt_models import PromptHistory, PromptType

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_advanced_analytics():
    """ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    
    print("ğŸ§ª ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 50)
    
    # í™˜ê²½ë³€ìˆ˜ ì„¤ì • (Docker ChromaDB ì‚¬ìš©)
    os.environ["CHROMA_DB_HOST"] = "localhost"
    os.environ["CHROMA_DB_PORT"] = "8001"
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    print("\nğŸ“š ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
    vector_service = VectorService()
    analytics_service = AdvancedAnalyticsService()
    prompt_service = PromptEnhancementService(vector_service)
    
    # 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ë°ì´í„° ìƒì„± ì¤‘...")
    test_prompts = [
        "Pythonìœ¼ë¡œ FastAPI ì„œë²„ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
        "React ì»´í¬ë„ŒíŠ¸ë¥¼ TypeScriptë¡œ êµ¬í˜„í•´ì£¼ì„¸ìš”",
        "ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„ë¥¼ ë„ì™€ì£¼ì„¸ìš”",
        "JWT ì¸ì¦ ì‹œìŠ¤í…œì„ êµ¬í˜„í•˜ê³  ì‹¶ì–´ìš”",
        "REST API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”",
        "í”„ë¡ íŠ¸ì—”ë“œ ìƒíƒœ ê´€ë¦¬ë¥¼ ì–´ë–»ê²Œ í•´ì•¼ í• ê¹Œìš”?",
        "Docker ì»¨í…Œì´ë„ˆí™” í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì£¼ì„¸ìš”",
        "CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì„±ì„ ë„ì™€ì£¼ì„¸ìš”",
        "ë³´ì•ˆ ì·¨ì•½ì ì„ ì ê²€í•˜ëŠ” ë°©ë²•ì€?",
        "ì„±ëŠ¥ ìµœì í™” ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”"
    ]
    
    project_id = "test-advanced-analytics"
    
    # í”„ë¡¬í”„íŠ¸ ì €ì¥
    stored_prompts = []
    for i, prompt_text in enumerate(test_prompts):
        prompt_history = PromptHistory(
            id=f"test-prompt-{i}",
            content=prompt_text,
            project_id=project_id,
            prompt_type=PromptType.USER_QUERY,
            created_at=datetime.now() - timedelta(days=i)
        )
        
        success = await vector_service.store_prompt_history(prompt_history)
        if success:
            stored_prompts.append(prompt_text)
            print(f"   âœ… ì €ì¥ë¨: {prompt_text[:30]}...")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {prompt_text[:30]}...")
    
    print(f"\nğŸ“Š ì´ {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ì €ì¥ ì™„ë£Œ")
    
    # 2. ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸
    print("\nğŸ” ê³ ê¸‰ ìœ ì‚¬ë„ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    try:
        # ë‘ í”„ë¡¬í”„íŠ¸ì˜ ì„ë² ë”© ìƒì„±
        emb1 = await vector_service._generate_embedding("Python FastAPI ì„œë²„ êµ¬í˜„")
        emb2 = await vector_service._generate_embedding("Pythonìœ¼ë¡œ ì›¹ ì„œë²„ ë§Œë“¤ê¸°")
        
        # ê³ ê¸‰ ìœ ì‚¬ë„ ê³„ì‚°
        similarity = await analytics_service.calculate_advanced_similarity(emb1, emb2)
        print(f"   ğŸ“ˆ ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {similarity:.4f}")
        
    except Exception as e:
        print(f"   âŒ ìœ ì‚¬ë„ ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    # 3. í”„ë¡¬í”„íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸
    print("\nğŸ—‚ï¸ í”„ë¡¬í”„íŠ¸ í´ëŸ¬ìŠ¤í„°ë§ í…ŒìŠ¤íŠ¸")
    try:
        # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê²€ìƒ‰
        prompts = await vector_service.search_similar_prompts(
            query="",
            project_id=project_id,
            limit=20
        )
        
        if len(prompts) >= 3:
            # ì„ë² ë”©ê³¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            embeddings = []
            texts = []
            for prompt in prompts:
                # ì‹¤ì œ ì„ë² ë”© ìƒì„±
                embedding = await vector_service._generate_embedding(prompt.get('content', ''))
                embeddings.append(embedding)
                texts.append(prompt.get('content', ''))
            
            # í´ëŸ¬ìŠ¤í„°ë§ ìˆ˜í–‰
            clustering_result = await analytics_service.cluster_prompts(
                prompt_embeddings=embeddings,
                prompt_texts=texts,
                n_clusters=3
            )
            
            print(f"   ğŸ“Š í´ëŸ¬ìŠ¤í„° ê°œìˆ˜: {len(clustering_result.get('clusters', []))}")
            print(f"   ğŸ“ˆ ì‹¤ë£¨ì—£ ì ìˆ˜: {clustering_result.get('silhouette_score', 0):.4f}")
            
            for i, cluster in enumerate(clustering_result.get('clusters', [])):
                print(f"   ğŸ—‚ï¸ í´ëŸ¬ìŠ¤í„° {i+1}: {cluster.get('size', 0)}ê°œ í”„ë¡¬í”„íŠ¸")
                print(f"      ëŒ€í‘œ: {cluster.get('representative_prompt', '')[:50]}...")
        else:
            print(f"   âš ï¸ í´ëŸ¬ìŠ¤í„°ë§ì„ ìœ„í•œ ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ({len(prompts)}ê°œ)")
            
    except Exception as e:
        print(f"   âŒ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
    
    # 4. TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸
    print("\nğŸ” TF-IDF í‚¤ì›Œë“œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    try:
        features_result = await analytics_service.extract_text_features(test_prompts)
        
        print(f"   ğŸ“š ì–´íœ˜ í¬ê¸°: {features_result.get('vocabulary_size', 0)}")
        
        top_features = features_result.get('top_features', [])
        if top_features:
            print("   ğŸ† ìƒìœ„ í‚¤ì›Œë“œ:")
            for feature in top_features[:10]:
                print(f"      - {feature.get('term', '')}: {feature.get('score', 0):.4f}")
        else:
            print("   âš ï¸ ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"   âŒ í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    # 5. íŠ¸ë Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
    print("\nğŸ“ˆ íŠ¸ë Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸")
    try:
        # ë©”íƒ€ë°ì´í„° í¬í•¨í•œ í”„ë¡¬í”„íŠ¸ ë°ì´í„° êµ¬ì„±
        prompt_data = []
        for i, prompt_text in enumerate(test_prompts):
            prompt_data.append({
                "content": prompt_text,
                "created_at": datetime.now() - timedelta(days=i),
                "prompt_type": "user_query"
            })
        
        trends = await analytics_service.analyze_prompt_trends(prompt_data)
        
        print(f"   ğŸ“Š ë¶„ì„ëœ í”„ë¡¬í”„íŠ¸ ìˆ˜: {trends.get('total_prompts', 0)}")
        
        # ì‹œê°„ íŒ¨í„´
        temporal = trends.get('temporal_patterns', {})
        if temporal:
            print(f"   ğŸ• í”¼í¬ ì‹œê°„: {temporal.get('peak_hour', 'N/A')}ì‹œ")
            print(f"   ğŸ“… í™œë™ ì‹œê°„ëŒ€: {temporal.get('total_hours', 0)}ì‹œê°„")
        
        # ê¸¸ì´ ë¶„í¬
        length = trends.get('length_distribution', {})
        if length:
            print(f"   ğŸ“ í‰ê·  ê¸¸ì´: {length.get('average_length', 0):.1f}ì")
            print(f"   ğŸ“ ìµœëŒ€ ê¸¸ì´: {length.get('max_length', 0)}ì")
        
        # ë³µì¡ë„
        complexity = trends.get('complexity_metrics', {})
        if complexity:
            print(f"   ğŸ§® í‰ê·  ë‹¨ì–´ ìˆ˜: {complexity.get('average_word_count', 0):.1f}")
            print(f"   ğŸ“ í‰ê·  ë¬¸ì¥ ìˆ˜: {complexity.get('average_sentence_count', 0):.1f}")
            
    except Exception as e:
        print(f"   âŒ íŠ¸ë Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}")
    
    # 6. í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ê°œì„  í…ŒìŠ¤íŠ¸
    print("\nğŸš€ í–¥ìƒëœ í”„ë¡¬í”„íŠ¸ ê°œì„  í…ŒìŠ¤íŠ¸")
    try:
        from models.prompt_models import PromptEnhanceRequest
        
        request = PromptEnhanceRequest(
            original_prompt="Python ì›¹ ì„œë²„ ë§Œë“¤ì–´ì¤˜",
            project_id=project_id,
            context_limit=5
        )
        
        result = await prompt_service.enhance_prompt(request)
        
        print(f"   ğŸ“Š ì‹ ë¢°ë„ ì ìˆ˜: {result.confidence_score:.4f}")
        print(f"   ğŸ’¡ ì œì•ˆì‚¬í•­ ìˆ˜: {len(result.suggestions)}")
        print(f"   ğŸ”— ì‚¬ìš©ëœ ì»¨í…ìŠ¤íŠ¸: {len(result.context_used)}ê°œ")
        
        if result.suggestions:
            print("   ğŸ’¡ ì£¼ìš” ì œì•ˆì‚¬í•­:")
            for suggestion in result.suggestions[:3]:
                print(f"      - {suggestion}")
                
    except Exception as e:
        print(f"   âŒ í”„ë¡¬í”„íŠ¸ ê°œì„  ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 50)
    print("ğŸ‰ ê³ ê¸‰ ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("\nğŸ“‹ ì‚¬ìš©ëœ scikit-learn ê¸°ëŠ¥ë“¤:")
    print("   - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (cosine_similarity)")
    print("   - K-í‰ê·  í´ëŸ¬ìŠ¤í„°ë§ (KMeans)")
    print("   - TF-IDF ë²¡í„°í™” (TfidfVectorizer)")
    print("   - ì‹¤ë£¨ì—£ ë¶„ì„ (silhouette_score)")
    print("   - ì°¨ì› ì¶•ì†Œ (PCA, t-SNE) - í–¥í›„ ì‹œê°í™”ìš©")

if __name__ == "__main__":
    asyncio.run(test_advanced_analytics()) 