import os
from typing import Optional
try:
    from pydantic_settings import BaseSettings
except ImportError:
    from pydantic import BaseSettings

class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    
    # ðŸ” OpenAI ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œë§Œ ê°€ì ¸ì˜¤ê¸°)
    openai_api_key: Optional[str] = None
    
    # ðŸ¤– ìž„ë² ë”© ëª¨ë¸ ì„¤ì •
    embedding_model_type: str = "deepseek"  # "openai" ë˜ëŠ” "deepseek"
    deepseek_api_base: str = "http://deepseek-r1:11434"  # DeepSeek R1 ì„œë²„ URL (Ollama ê¸°ë³¸ í¬íŠ¸)
    deepseek_embedding_model: str = "nomic-embed-text"  # ìž„ë² ë”© ì „ìš© ëª¨ë¸
    deepseek_llm_model: str = "r1-1776:latest"  # LLM ì „ìš© ëª¨ë¸
    local_embedding_model_path: Optional[str] = None
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
    
    # ðŸ“Š ë²¡í„° DB ì„¤ì • (Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ)
    chroma_db_path: str = "/data"
    
    # ðŸŒ ì„œë²„ ì„¤ì •
    host: str = "0.0.0.0"
    port: int = 8000  # FastMCP ì„œë²„ í¬íŠ¸
    
    # ðŸ“ ë¡œê¹… ì„¤ì •
    log_level: str = "INFO"
    log_dir: str = "/app/logs"  # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ë¡œê·¸ ê²½ë¡œ
    
    # ðŸš€ MCP ì„¤ì •
    mcp_server_name: str = "FastMCP Prompt Enhancement Server"
    mcp_version: str = "2.0.0"
    
    # ðŸ” ChromaDB ì„¤ì •
    chroma_host: str = "chromadb"  # Docker Compose ì„œë¹„ìŠ¤ëª…
    chroma_port: int = 8000       # ChromaDB í¬íŠ¸
    chroma_collection_name: str = "prompts"
    
    # ðŸ§  AI ì„¤ì •
    max_context_length: int = 5
    similarity_threshold: float = 0.7
    
    # ðŸ“ˆ ë¶„ì„ ì„¤ì •
    enable_advanced_analytics: bool = True
    clustering_algorithm: str = "kmeans"
    max_clusters: int = 10
    
    # âš¡ ì„±ëŠ¥ ìµœì í™” ì„¤ì •
    # ìºì‹± ì„¤ì •
    enable_search_cache: bool = True
    cache_ttl_seconds: int = 300  # 5ë¶„
    max_cache_size: int = 1000    # ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
    
    # ë¹„ë™ê¸° ì²˜ë¦¬ ì„¤ì •
    max_concurrent_requests: int = 50  # 10 â†’ 50ìœ¼ë¡œ ì¦ê°€
    request_timeout_seconds: int = 60  # 30 â†’ 60ìœ¼ë¡œ ì¦ê°€
    
    # ìž„ë² ë”© ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •
    embedding_batch_size: int = 100  # 50 â†’ 100ìœ¼ë¡œ ì¦ê°€
    max_concurrent_embeddings: int = 20  # ìƒˆë¡œ ì¶”ê°€
    
    # íŒŒì¼ ì²˜ë¦¬ ìµœì í™” ì„¤ì •
    max_concurrent_files: int = 100  # ìƒˆë¡œ ì¶”ê°€
    file_batch_size: int = 200  # ìƒˆë¡œ ì¶”ê°€
    chunk_overlap_ratio: float = 0.1  # ìƒˆë¡œ ì¶”ê°€
    
    # ë²¡í„° DB ìµœì í™” ì„¤ì •
    chroma_batch_size: int = 500  # ìƒˆë¡œ ì¶”ê°€
    enable_parallel_indexing: bool = True  # ìƒˆë¡œ ì¶”ê°€
    
    # ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
    max_file_size_mb: int = 50  # ìƒˆë¡œ ì¶”ê°€
    enable_file_compression: bool = True  # ìƒˆë¡œ ì¶”ê°€
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í’€ë§
    db_connection_pool_size: int = 10
    db_connection_timeout: int = 30
    
    # ê²€ìƒ‰ ìµœì í™”
    search_result_cache_ttl: int = 300
    similarity_search_algorithm: str = "cosine"
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ (íŠœë„ˆë¸”)
    hybrid_semantic_weight: float = 0.7
    hybrid_keyword_weight: float = 0.3
    recency_weight: float = 0.1
    complexity_weight: float = 0.1
    # TF-IDF ì¸ë±ìŠ¤ TTL (ì´ˆ)
    tfidf_index_ttl_seconds: int = 300
    
    # ì†ë„ ì œí•œ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€)
    rate_limit_per_minute: int = 600  # ë¶„ë‹¹ ìš”ì²­ ìˆ˜
    rate_limit_burst_size: int = 100  # ë²„ìŠ¤íŠ¸ í¬ê¸°
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬ ì„¤ì • (ìƒˆë¡œ ì¶”ê°€)
    enable_memory_optimization: bool = True
    max_memory_usage_mb: int = 2048  # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
    max_cpu_usage_percent: float = 80.0  # ìµœëŒ€ CPU ì‚¬ìš©ë¥ 
    garbage_collection_threshold: int = 100  # GC íŠ¸ë¦¬ê±° ìš”ì²­ ìˆ˜
    slow_query_threshold_seconds: float = 2.0  # ëŠë¦° ì¿¼ë¦¬ ìž„ê³„ê°’
    
    # ë°±ê·¸ë¼ìš´ë“œ ìž‘ì—… ì„¤ì •
    enable_background_tasks: bool = True
    background_task_interval: int = 60
    
    # ðŸ”„ í”¼ë“œë°± ì‹œìŠ¤í…œ ì„¤ì •
    feedback_learning_rate: float = 0.1  # í•™ìŠµë¥  (0.0 ~ 1.0)
    feedback_decay_rate: float = 0.95  # ì‹œê°„ì— ë”°ë¥¸ í”¼ë“œë°± ê°€ì¤‘ì¹˜ ê°ì†Œ
    min_feedback_count: int = 3  # ìµœì†Œ í”¼ë“œë°± ìˆ˜
    feedback_confidence_threshold: float = 0.7  # í”¼ë“œë°± ì‹ ë¢°ë„ ìž„ê³„ê°’
    enable_feedback_learning: bool = True  # í”¼ë“œë°± í•™ìŠµ í™œì„±í™”
    feedback_retention_days: int = 90  # í”¼ë“œë°± ë³´ì¡´ ê¸°ê°„
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

# ì „ì—­ ì„¤ì • ì¸ìŠ¤í„´ìŠ¤
settings = Settings()

# í˜¸í™˜ì„±ì„ ìœ„í•œ Config í´ëž˜ìŠ¤ ìƒì„±
class Config:
    """ì •ì  ì„¤ì • í´ëž˜ìŠ¤ (í˜¸í™˜ì„± ìœ ì§€)"""
    
    @property
    def FEEDBACK_LEARNING_RATE(self) -> float:
        return settings.feedback_learning_rate
        
    @property
    def FEEDBACK_DECAY_RATE(self) -> float:
        return settings.feedback_decay_rate
        
    @property
    def MIN_FEEDBACK_COUNT(self) -> int:
        return settings.min_feedback_count
        
    @property
    def FEEDBACK_CONFIDENCE_THRESHOLD(self) -> float:
        return settings.feedback_confidence_threshold 